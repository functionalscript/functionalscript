# Call-like instructions

Call-like bytecode instructions include following groups:

1. **calls into host functions** (standard language runtime "intrinsics", including operators);
2. **static calls into user-defined functions**;
3. **dynamic calls into user-defined functions**;
4. **other call-like instructions** (mentioned here thanks to similarities to above mentioned
groups).

Call-like instructions use lists of argument descriptors that will be considered later in this
document.

## 1. Calls into host functions

Each host function has a stable identification (e.g. a numeric id predefined within a given FS
release) and runtime metadata specifying among other things its number of parameters and whether or
not it returns a result.

The interpreter accesses metadata upon decoding the starting part of a call instruction. Knowing the
number of parameters and result presence flag, it continues decoding argument instructions filling
out an internal data structure best fit for the given host function. For example,

```js
const c = a + b
```

produces bytecode for calling host's implementation of operator plus, followed by slot
descriptors for `a`, `b` and `c` at the caller function's stack frame. This allows to execute that
built-in function without overhead of copying `a`, `b` to the top of the stack and then copying
the result to the caller stack frame slot allocated for `c`.

A schema for a host function call looks like

`<host call instruction> <predefined host function id> <list of argument descriptors>`

Most of host functions have a number of arguments predefined for the given functions, thus the VM
processes exactly that number of argument descriptors one after another; the number of arguments is
not present in bytecode in these cases. Note that the parser has an option to reject erroneous code
with incorrect number of arguments passed to such host function - or use a recovery strategy; in
any case it is guaranteed that the number of arguments in bytecode is always correct.

Remaining host functions have variadic lists of arguments, for example, `Math.max` can take any
number of arguments. For such calls, the parser prepends the list of argument descriptors with
the number of arguments passed at the caller side.

## 2. Static calls into user-defined functions

In case when bytecode generator has complete information of a function being called, a reference
to that function is resolved at load time &ndash; in this case the call instruction identifies
the callee user-defined function by an integer key to the correspondent lookup table built at load
time.

A schema for a static call differs from the schema for a host function call in two aspects:

- The function id is not predefined; that number is generated by the parser and is backed with
a correspondent entry in one of metadata tables produced by the parser alongside with bytecode
instructions.

- The parser explicitly specifies the number of arguments passed at the caller side, providing
exactly that number of argument descriptors.

`<static call instruction> <runtime function id> <list of arguments with explicitly defined length>`

A generic static call instruction provides the number of arguments right after function's id,
and then lists exactly that number of argument descriptors. However when we care about bytecode
compactness, we should consider several special-cased "shorthand" static call instructions &ndash;
for example, we can have 4 separate instructions for 1) zero argument calls, 2) one argument calls,
3) two argument calls and 4) three argument calls. Calls with larger number of arguments are backed
by the generic static call instruction.

TODO: provide FS code snippet here.

## 3. Dynamic calls into user-defined functions

Sometimes the parser cannot determine the callee function object statically (at parse time). For
example, that function object gets retrieved as a property of an object by a dynamic lookup
(with property named not known at parse time but calculated at run time), or as an element of
an array, or as a result of another function call.

In this case the function object is identified by its location descriptor akin to to location-
based argument descriptors. That descriptor is followed by argument descriptors in
same way as in the static call instruction. In a way, we can consider the function object
descriptor as the first always-existing argument descriptor, but it makes sense to separate
it out and then have exactly same argument list descriptor for zero or more arguments.

`<dynamic call instruction> <function object location descriptor> <list of argument descriptors
with explicitly defined length>`

As with static call instructions described in the previous section, we can add shorthand dynamic
call instructions for cases with small number of arguments, using the generic instruction for calls
with larger number of arguments.

TODO: provide FS code snippet here.

## 4. Other call-like instructions

There are instructions that are not host function calls technically since they do not correspond
to language's predefined functions and operators. Yet they are provided with a list of argument
descriptors of a predefined length in the same way as the host function calls. For example,
the copy instruction and the move instruction each have exactly two argument descriptors &ndash; one
for the source and another for the destination (side note: the move instruction nullifies
the source, not increasing the number of references in case of moving a reference; the copy
instruction keeps the source intact and thus increases the number of references when copying
a reference).

For the sake of simplicity we can use the host function call scheme for these call-like instructions
&ndash; and even consider zero-argument instructions as host function calls. Alternatively, we will
have a wider set of instruction code and use the following schema for call-like instructions:

`<call-like instruction> <predefined number of argument descriptors>`

Some call-like instructions have variadic argument lists: good examples are instructions that create
arrays and objects. Such instructions place the number of arguments right after the instruction,
then providing exact that number of argument descriptors. As before, we might want to consider
shorthand instructions for cases with small number of elements in the compound object being created.

TODO: we should keep on the table the normal Polish notation idea for instructions, with that
the example in the previous paragraph does not play well. Wiht the normal Polist notation there is
a struture of nested commands: e.g. we start with a command to create a new N-element array and that
command has N nested command specifying element values. As the result of execution of that compound
we get the newly created and initialized array available.

## 5. Argument descriptors

For starters, there are two kinds of argument descriptors &ndash; immediate arguments (for constants
of basic non-reference types) and non-immediate arguments (for values stored at various run-time
locations). Considering the fact that there are also several types of run-time locations, it makes
sense to have one enumerator of argument kinds that has a special value for immediate arguments and
then several values one per location type:

1. **Immediate arguments**: that kind of descriptor contains the base type constant value right in
the descriptor. We can use a variable length encoding here or use a 64-bit value always with NaNVM's
scheme of encoding base value type within that value. From the flexibility point of view it makes
sense to not take dependency on NaNVM's scheme of encoding base values and use the benefit of
compactness of a variable length encoding scheme here.
2. **Caller's local values**: that is a kind of location descriptors referring to locations the
caller function's frame. We don't use this kind of descriptors for other frames in the caller chain,
nor for the "global frame" - only for locals of the immediate caller. Within that frame, locations
are indexed by unsigned integers starting from zero. One would say that these locations correspond
one to one to named locals, but that would prohibit a frame slot reuse optimization that the parser
can implement, so we don't use this analogy.
3. **Caller's temporary values**: that is a kind of location used for caller's temporary values,
typically produced dynamically "on the stack" when calculating expressions. These locations are
zero-based indexes with zero corresponding to the top of the stack and greater unsigned integer
indexes corresponding to deeper stack locations counting from the top of the stack. The VM might
decide to combine function's frame of locals with the stack of temporary values, but that is an
implementation detail of that VM so other implementations can use another approach, completely
separating two location kinds.
4. **Captured values**: that kind of location is used when the user-defined caller function refers
to value names that are not locally defined in it, but rather belong to outer contexts. We cannot
use a scheme that describes a value belonging to the frame "up in the caller chain" because, after
being defined, a function object can be detached from the call chain context and then be passed
into another, different context where the original caller chain references are not relevant anymore.
So, when detecting a reference to an outer context within a function body, the parser registers it
as a captured value. Captured values are stored in a devoted block of slots owned by the function
object. Naturally, that frame is separate from other location kinds described here: its lifetime
(coinciding with the function object's lifetime) is different. It gets created and initialized at
the moment of the owning function object's creation.

TODO: Regarding #4 above: consider a recursive function that captures outer context values, how
will that fit into the schema described above?
```JS
const a = () { b() }
// a() here triggers compilation error: b is not defined at this point
const b = () { a() }
a() // this is OK at compile time, even though triggers stack overflow / infinite loop at run time
```

It is tempting to introduce also yet another kind of location that corresponds to arguments of
the caller function. However, each parsed function either has a fixed number of arguments &ndash;
that occupy first slots of its stack frame &ndash; or a variable number of arguments (addressable
within that function's body via `arguments` array). In the latter case the VM creates an array
object referred as `arguments` and places a reference to that object to the zeroth slot of callee's
stack frame. The VM distinguishes two cases via looking up metadata of the callee function object.
See details below in the section **behind the scenes of user-defined function calls**.

Thus, the list of argument descriptor kinds stays as of now at 4 values (2 bits). Where do we place
a 2-bit argument descriptor kind value for each argument remains an open question. If we prioritize
bytecode compactness, it makes sense to merge that 2-bit value with the proper data of an argument
descriptor.

For example, assuming that indexes of argument slots for 2 location kinds are in most cases small
numbers, we can use one byte for such an argument descriptor. In that byte two leading bits
designate location kind while remaining 6 bits allow for an index in the range from 0 to 62
(reserving the value 63 for overflow cases of slot indexes larger that 62; in such cases that
larger index is provided in the following bytes). That scheme can be expanded to the case of
immediate arguments that we don't dive into here.

But if we aim for simplicity, it might make sense to provide a sequence of argument descriptor kinds
upfront, then using simple encoding for each argument descriptor after that.

## 6. Behind the scenes of user-defined function calls

When the parser finalizes processing of a function body, it creates function's metadata that among
other things indicates, does this function use `arguments` array, or does not? Let's name functions
that use that array "variadic" and other functions "non-variadic" (note: each non-variadic function
has its number of parameters in metadata). The VM looks up that flag when it processes a call
instruction; for non-variadic functions it looks up also function's number of parameter. Let's
consider several cases here.

### 6.1. Calls into variadic functions

Each variadic function reserves exactly one slot of its stack frame to access arguments - the zeroth
slot that contains a reference to the `arguments` array. While processing a call to such function
the VM creates a new array of the size equal to the number of arguments in the call instruction.
The VM processes argument descriptors, initializing all elements of that newly created array. The
one and only reference to that array gets moved to the zeroth slot of the callee's stack frame, and
that is all what needs to be done - all other slots of callee's stack frame are used for callee's
locals.

### 6.2. Calls into non-variadic functions

Each non-variadic function reserves a given number of its stack frame slots, at the beginning. Other
stack frame slots are used for locals. When processing a call into such a non-variadic function,
the VM starts with a state with all callee's parameter stack frame slots being default-initialized
(by `undefined` values to follow ECMAScript standard). In case when the number of arguments is not
greater than the number of parameters (that VM looks up in function's metadata), the VM fills out
correspondent stack frame slots (leaving remaining slots with `undefined` values when the number
of arguments is less than the number of parameters). When reaching the number of parameters (while
the number of arguments is greater than the number of parameters) the VM keeps processing remaining
argument descriptors, doing nothing &ndash; since the callee does not do anything with extra
arguments. Still the VM has to "skip" remaining arguments to reach the next bytecode instruction
after the end of the argument descriptor list.

### 6.3. Stack frame allocation strategies

First, let's postpone the idea of placing the stack of function's temporary values in the stack
frame, focusing on locals only.

A simple VM implementation calculates the size of a function body's stack frame by allocating one
slot for each local in the body, maybe reusing slots in cases when one local stops being used at
some well defined pont within the body, so another local defined below that point can safely reuse
same slot. When finishing body processing, the parser places the required capacity of
function's stack frame into function's metadata. When processing a call into that function, the VM
allocates a new array with the given capacity, switching to that array as the current stack frame
slot, and keeping a reference to caller's stack frame array to switch back when the control flow
returns from the callee to the caller (at which moment the callee's stack frame gets disposed). This
simple implementation allows for recursive calls quite naturally, but requires lots of allocations.

That simple scheme does not make difference between calls of static and dynamic user-defined
functions. Let's make a note that dynamic function calls always require callee's stack frame
allocation since the identity of the callee is not known at parse time. However, in a codebase with
rare / absent dynamic calls the parser and the VM can implement a more complicated scheme that
reduces the number of call stack allocations.

There is a straightforward variation of the simple scheme that tracks the common call stack as
a list of large continuous fixed-size blocks. When processing a call, the VM compares callee's
stack frame size with the remainder of unoccupied slots at the end of the current block, and
allocates the new stack frame within that block if it fits. If the new stack frame does not fit,
the VM adds a new block to the list and allocates the new stack frame at the beginning of that new
block. Note that there will be some waste at unused reminders of blocks.

In a more complicated scheme, a user-defined function that does not call other user-defined
functions (a "leaf" functions of rank 0) has a well-defined stack frame capacity. Now, considering
the next layer of user-defined functions (of rank 1) that call only rank 0 functions, the parser can
calculate a compound stack frame capacity for each rank 1 function, pre-allocating stack frames of
rank 0 callees as sub-ranges of stack frames of caller functions of rank 1. Than rank 2 functions
could be figured out and so on &ndash; with a caveat of recursive cases where new stack frame
allocations are still necessary.

Regarding the stack of temporary values: the parser can track its size at various points while
analyzing a function body, and reserve some extra slots within the planned stack frame &ndash; to
keep temporary values in the same array of slots (with a correspondent logic implemented on the VM
side). Alternatively the VM can manage a separate dynamic data structure for temporary values in
this or that way (e.g. using a list of blocks for a joint stack as described above); in that case
the parser does not need to track temporary values data. Since we use two different kinds of
argument descriptor locations for locals and for temporary values, various VM / parser
implementation decisions are possible for the same bytecode specification.
